{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a5182ef-d7a8-4765-8172-b99d68a0a8f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ultralytics in /home/anderste/.local/lib/python3.10/site-packages (8.3.23)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.24.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/anderste/.local/lib/python3.10/site-packages (from ultralytics) (3.8.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/anderste/.local/lib/python3.10/site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/anderste/.local/lib/python3.10/site-packages (from ultralytics) (2.2.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/anderste/.local/lib/python3.10/site-packages (from ultralytics) (0.17.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/anderste/.local/lib/python3.10/site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.4)\n",
      "Requirement already satisfied: py-cpuinfo in /home/anderste/.local/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/anderste/.local/lib/python3.10/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/anderste/.local/lib/python3.10/site-packages (from ultralytics) (2.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/anderste/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/anderste/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/anderste/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/anderste/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
      "Requirement already satisfied: filelock in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/anderste/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/anderste/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.3.101)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/anderste/.local/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e21e7ec-9707-41d4-a021-4c98e8c01731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0a6f9b7-04d8-4805-bf3c-b0ce67023e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['tench', 'goldfish', 'white shark', 'electric ray', 'stingray', 'cock', 'hen']\n",
      "Starting training with YAML: ./data.yaml\n",
      "New https://pypi.org/project/ultralytics/8.3.27 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.23 ðŸš€ Python-3.10.12 torch-2.2.0+cu121 CUDA:0 (Tesla V100-SXM3-32GB, 32494MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=weights/yolov8n.pt, data=./data.yaml, epochs=20, time=None, patience=100, batch=60, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train68, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/dataset/runs/detect/train68\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7de32a147490>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anderste/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/anderste/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 225 layers, 3,012,213 parameters, 3,012,197 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/dataset/runs/detect/train68', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/train/labels.cache... 1315 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1315/1315 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/valid/labels.cache... 376 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 376/376 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/dataset/runs/detect/train68/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00046875), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/dataset/runs/detect/train68\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20        10G      1.552       4.16      1.098        208        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684     0.0124      0.575     0.0994     0.0604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      8.67G      1.506      2.423      1.048        341        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.011      0.702      0.288      0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      8.53G      1.482      2.063      1.055        285        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.941     0.0698      0.357      0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      8.73G       1.46       1.88      1.045        290        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.649      0.235      0.368      0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      9.23G      1.462      1.776      1.047        177        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.637      0.428      0.452      0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20       9.3G      1.445      1.622      1.045        284        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.496      0.495      0.521      0.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      9.32G      1.435      1.521      1.032        347        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.432       0.54      0.514      0.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      8.56G      1.414      1.399      1.032        376        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.549      0.582      0.629      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      9.07G      1.374      1.308      1.018        292        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684       0.63      0.732      0.694      0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      8.53G      1.402      1.277      1.023        264        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  3.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684       0.69      0.614      0.668      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20       8.5G      1.378      1.286      1.036        167        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.564      0.656       0.66      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      8.56G      1.362      1.206      1.033        263        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.598      0.678      0.718      0.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20       8.7G      1.359      1.191      1.031        241        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.718      0.699      0.722      0.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      8.44G      1.322      1.129      1.018        199        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.722      0.775       0.78      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      8.41G      1.308      1.089      1.009        269        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.786      0.727       0.78      0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      8.56G      1.304      1.035      1.013        162        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.737      0.746      0.788      0.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      8.49G      1.284      1.001      1.002        249        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.757      0.759      0.797      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      8.63G      1.271     0.9913     0.9957        177        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.702       0.78      0.793      0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      8.57G      1.248     0.9538     0.9946        202        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.749      0.807      0.812      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20       8.6G      1.238     0.9238     0.9839        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.776      0.797       0.82      0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.045 hours.\n",
      "Optimizer stripped from /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/dataset/runs/detect/train68/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/dataset/runs/detect/train68/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/dataset/runs/detect/train68/weights/best.pt...\n",
      "Ultralytics 8.3.23 ðŸš€ Python-3.10.12 torch-2.2.0+cu121 CUDA:0 (Tesla V100-SXM3-32GB, 32494MiB)\n",
      "Model summary (fused): 168 layers, 3,007,013 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       1684      0.776      0.797      0.821      0.588\n",
      "                 tench        271       1243      0.751      0.792      0.804      0.469\n",
      "              goldfish         92        202       0.75      0.564      0.711      0.472\n",
      "           white shark         28         28      0.792      0.964      0.925       0.53\n",
      "          electric ray         14         14      0.817      0.857      0.767      0.737\n",
      "              stingray         40         45      0.832      0.733      0.881       0.49\n",
      "                  cock         41        117      0.567      0.726      0.708      0.584\n",
      "                   hen         34         35      0.924      0.943      0.956      0.835\n",
      "Speed: 0.2ms preprocess, 0.6ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1m/home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/dataset/runs/detect/train68\u001b[0m\n",
      "\n",
      "image 1/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1003_png.rf.f1ea6fe4d3cbf87e91ea60199369eed2.jpg: 640x640 1 tench, 1 white shark, 10.0ms\n",
      "image 2/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1005_png.rf.c858f010ae1ef6e3dbf58f9e87582d36.jpg: 640x640 (no detections), 12.9ms\n",
      "image 3/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/100_png.rf.b68072c82acf9bc66e97c6a679198aef.jpg: 640x640 23 tenchs, 6 cocks, 6.1ms\n",
      "image 4/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1037_png.rf.0a2a4bb0a783063a09e7639ee8b11d5a.jpg: 640x640 2 tenchs, 6.0ms\n",
      "image 5/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/104_png.rf.0dd2053aceb41d45a9865be142e8fe10.jpg: 640x640 8 tenchs, 5 cocks, 1 hen, 7.2ms\n",
      "image 6/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1066_png.rf.d0d7a44eb5d33aa3b7d3a4cf8ff2a505.jpg: 640x640 1 tench, 2 white sharks, 10.3ms\n",
      "image 7/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1067_png.rf.0b3742a8d0258292fa6ba7c683b30465.jpg: 640x640 1 tench, 7.0ms\n",
      "image 8/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1092_png.rf.abe751eb246bc8454ccb7b8324997e91.jpg: 640x640 1 tench, 1 white shark, 6.2ms\n",
      "image 9/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1097_png.rf.c5501e996439425c797534c104a2100a.jpg: 640x640 2 tenchs, 1 white shark, 5.9ms\n",
      "image 10/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1103_png.rf.642a320cb1ad304704fcb69096550de5.jpg: 640x640 2 tenchs, 2 white sharks, 5.6ms\n",
      "image 11/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1115_png.rf.2d5a9ca47bce9abd2fc06decfe1e168d.jpg: 640x640 1 tench, 1 white shark, 5.9ms\n",
      "image 12/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/113_png.rf.82cb2f3fadde658fd52f7419ab475f5f.jpg: 640x640 16 tenchs, 7.9ms\n",
      "image 13/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1140_png.rf.a3cc72d12b6a9b3309f0f72f7793d597.jpg: 640x640 1 tench, 7.9ms\n",
      "image 14/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1157_png.rf.4b08fc622d7db7c1c5d2ab39788ab385.jpg: 640x640 1 white shark, 10.3ms\n",
      "image 15/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1168_png.rf.95584643829ef63c69e73d9fe21934d0.jpg: 640x640 1 white shark, 6.4ms\n",
      "image 16/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1202_png.rf.4cd3afec687575a2be917bc70f121aae.jpg: 640x640 1 white shark, 6.0ms\n",
      "image 17/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1205_png.rf.1a13c76ba75efcc7c77778b8e6b48e23.jpg: 640x640 1 white shark, 5.8ms\n",
      "image 18/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1223_png.rf.6290126a1d02e9cc2594dcaad6e2c4d0.jpg: 640x640 (no detections), 10.3ms\n",
      "image 19/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1224_png.rf.d26c9de710e31fa2343c7138bdfe37b2.jpg: 640x640 1 goldfish, 1 cock, 10.6ms\n",
      "image 20/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1231_png.rf.ded98dd66f96b5a130b3574ab50e70c9.jpg: 640x640 1 tench, 6.9ms\n",
      "image 21/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1244_png.rf.70539f0ce092ddcea5f48c28e7e26a3e.jpg: 640x640 2 tenchs, 6.1ms\n",
      "image 22/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1252_png.rf.af0acbf24af1c234a9273b247b2dc3f0.jpg: 640x640 2 goldfishs, 5.8ms\n",
      "image 23/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1257_png.rf.455b010250bc433a8c52fa475383d77c.jpg: 640x640 1 goldfish, 6.0ms\n",
      "image 24/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1272_png.rf.9d2fa60ee06ef976f4aa3c7f248f307c.jpg: 640x640 1 goldfish, 10.2ms\n",
      "image 25/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1275_png.rf.20738a8625755a555c40d99f4b794c57.jpg: 640x640 1 tench, 8.7ms\n",
      "image 26/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1291_png.rf.0aec2075b681be0c29a2e234eda7c1a9.jpg: 640x640 1 tench, 11.0ms\n",
      "image 27/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/129_png.rf.a412ccf2f585210469ffccd86696e7c7.jpg: 640x640 20 tenchs, 4 cocks, 6.4ms\n",
      "image 28/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1301_png.rf.543739162cc9930b60a44cf945ad24d8.jpg: 640x640 1 tench, 6.0ms\n",
      "image 29/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1336_png.rf.d36eaec64577649bc0e5816f8f6120fe.jpg: 640x640 1 goldfish, 6.0ms\n",
      "image 30/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1340_png.rf.235ee0ccc9dd4afb43a924da41259b0c.jpg: 640x640 1 goldfish, 9.3ms\n",
      "image 31/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1351_png.rf.c41c61af6394632661f2aefe6f9ffe53.jpg: 640x640 1 goldfish, 9.1ms\n",
      "image 32/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1355_png.rf.0067a574f5d00ebe647162aacd4a4a70.jpg: 640x640 1 goldfish, 6.9ms\n",
      "image 33/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1372_png.rf.de541a78be50efd38ec3e42489a83f89.jpg: 640x640 2 tenchs, 6.2ms\n",
      "image 34/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1378_png.rf.c5895dcd8dba75c1a0336bfdb302406b.jpg: 640x640 1 goldfish, 5.7ms\n",
      "image 35/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1389_png.rf.13a5fa519891eb5ec5d6b1afa1a490d8.jpg: 640x640 1 goldfish, 5.9ms\n",
      "image 36/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1402_png.rf.367bebdb746a2c03747ab6d878bcaa2d.jpg: 640x640 1 tench, 1 goldfish, 7.0ms\n",
      "image 37/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1403_png.rf.58f20342f6e7087e21f5bef847e9f29d.jpg: 640x640 1 tench, 9.8ms\n",
      "image 38/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/140_png.rf.3c0cd57fe9a22983cad9cfa27d5bea6b.jpg: 640x640 59 tenchs, 10 cocks, 10.9ms\n",
      "image 39/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1410_png.rf.ec030aba5027d11b0bb1c9b4b4aaf46f.jpg: 640x640 1 tench, 6.4ms\n",
      "image 40/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1412_png.rf.deeb34b3f182bfebe24a67d3f67f5747.jpg: 640x640 1 tench, 1 goldfish, 6.1ms\n",
      "image 41/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1422_png.rf.455cafa10400015f480a92e11471cd26.jpg: 640x640 1 tench, 6.0ms\n",
      "image 42/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1427_png.rf.cb420d029691567f45c2869301557038.jpg: 640x640 1 stingray, 8.9ms\n",
      "image 43/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1428_png.rf.9610288c7debaed82e41063e3569af66.jpg: 640x640 1 stingray, 10.0ms\n",
      "image 44/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1458_png.rf.67b0112ca02348216139b8d24796ee93.jpg: 640x640 1 goldfish, 7.3ms\n",
      "image 45/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1459_png.rf.a9b664a1bf4f0428b833a81319f41595.jpg: 640x640 1 goldfish, 6.3ms\n",
      "image 46/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1463_png.rf.86bc57dbc906efde4bf9efd599033a3b.jpg: 640x640 1 goldfish, 6.1ms\n",
      "image 47/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1485_png.rf.c21af7ee5024b5479fa56e97a96594a2.jpg: 640x640 (no detections), 6.0ms\n",
      "image 48/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/14_png.rf.01e159afe7e32604eb21edc6f6834084.jpg: 640x640 4 tenchs, 1 electric ray, 1 hen, 7.2ms\n",
      "image 49/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1510_png.rf.84292e25c4dc7cb138f2d910dafe56de.jpg: 640x640 1 goldfish, 6.7ms\n",
      "image 50/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1511_png.rf.113235ffdc2685ea9d0c835e6d2ca057.jpg: 640x640 1 goldfish, 10.8ms\n",
      "image 51/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1520_png.rf.d8efe42bad7b3527102c29e609369b33.jpg: 640x640 1 tench, 6.4ms\n",
      "image 52/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1521_png.rf.ce9bccbfc4c13abd727b7c6f9f1c3ba7.jpg: 640x640 1 tench, 6.1ms\n",
      "image 53/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1525_png.rf.b4bfa94d280cc375828eb2b476ee8002.jpg: 640x640 1 goldfish, 6.0ms\n",
      "image 54/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1532_png.rf.1e7cc21da531c13650623fbe94f86757.jpg: 640x640 1 goldfish, 6.2ms\n",
      "image 55/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1533_png.rf.3cbbbca27b866e7978a44a27fa117567.jpg: 640x640 1 goldfish, 12.5ms\n",
      "image 56/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/154_png.rf.0a90675d73c7c169767e7fa659da0b36.jpg: 640x640 17 tenchs, 2 cocks, 9.7ms\n",
      "image 57/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1581_png.rf.030b0ceacd79e41c13622de74f3e2ddd.jpg: 640x640 1 goldfish, 6.6ms\n",
      "image 58/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1585_png.rf.7190df7bcadd5f451e7d1eecf9edadf4.jpg: 640x640 1 goldfish, 6.0ms\n",
      "image 59/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1586_png.rf.fe974c10e13581e7b6d3971dcc7e77b2.jpg: 640x640 1 goldfish, 5.9ms\n",
      "image 60/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1601_png.rf.7dae1835ef809e6954f083662485a135.jpg: 640x640 5 goldfishs, 6.0ms\n",
      "image 61/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1603_png.rf.64e5364194318b35611bb3b6a3cf81ca.jpg: 640x640 7 goldfishs, 7.1ms\n",
      "image 62/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1622_png.rf.3940cb25387e920efb995f9a9b25a9be.jpg: 640x640 1 tench, 2 goldfishs, 10.8ms\n",
      "image 63/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1645_png.rf.9acbafbb1102e7a2e85842b4e272bd48.jpg: 640x640 3 tenchs, 1 goldfish, 7.1ms\n",
      "image 64/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1649_png.rf.cccfe3c7788ab09da3908eb4cfc043bd.jpg: 640x640 3 tenchs, 6.4ms\n",
      "image 65/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1654_png.rf.6f834f488b27d5857c31aeeb859c697e.jpg: 640x640 3 goldfishs, 5.8ms\n",
      "image 66/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1661_png.rf.9ba0260f862066d1450e66828e7ac019.jpg: 640x640 2 tenchs, 1 goldfish, 5.9ms\n",
      "image 67/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1662_png.rf.9a40952efaaba53d1e72d85233b7393a.jpg: 640x640 3 tenchs, 1 goldfish, 9.0ms\n",
      "image 68/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1666_png.rf.dc387ec896dd2065de1a29eee596a2b3.jpg: 640x640 2 tenchs, 9.8ms\n",
      "image 69/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1677_png.rf.b82f52080b60765ab279ad4e67382cc2.jpg: 640x640 2 tenchs, 3 goldfishs, 6.8ms\n",
      "image 70/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1683_png.rf.5bdc9ed817a5436a06d44c503d8aa7ab.jpg: 640x640 4 tenchs, 1 goldfish, 6.4ms\n",
      "image 71/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1688_png.rf.70acde7d667010bf04267c46cce85a8c.jpg: 640x640 9 tenchs, 5 goldfishs, 6.2ms\n",
      "image 72/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1699_png.rf.17764f003081f9be44e10ba117a90968.jpg: 640x640 6 tenchs, 2 goldfishs, 6.1ms\n",
      "image 73/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/169_png.rf.d4a2fb8d8fd6e02adb663256d3f2c130.jpg: 640x640 2 tenchs, 7.4ms\n",
      "image 74/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1704_png.rf.708bd177774ace9b1064135576582145.jpg: 640x640 9 tenchs, 1 goldfish, 13.3ms\n",
      "image 75/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1731_png.rf.cbec24d9ae504a110b4871b725aba9d8.jpg: 640x640 2 tenchs, 5 cocks, 6.6ms\n",
      "image 76/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1735_png.rf.1f5264eaa5eb329aaaf3f78a59e1c800.jpg: 640x640 2 tenchs, 2 cocks, 6.3ms\n",
      "image 77/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1736_png.rf.1c1903ca3017b7052d3c3c9b7b51602d.jpg: 640x640 2 tenchs, 1 hen, 6.0ms\n",
      "image 78/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1738_png.rf.8631a131f04f9ecd1a1aa42d93f6cd58.jpg: 640x640 1 tench, 1 electric ray, 2 cocks, 6.0ms\n",
      "image 79/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1746_png.rf.4fb3a5138417af3dcf38387ef33d1645.jpg: 640x640 3 tenchs, 10.7ms\n",
      "image 80/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1753_png.rf.e2b8f2bab23c610fdfec781eccd74b37.jpg: 640x640 1 tench, 1 cock, 1 hen, 9.1ms\n",
      "image 81/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1768_png.rf.497e55b1e15fe0e40f0e4660dea241ce.jpg: 640x640 7 tenchs, 4 cocks, 1 hen, 7.4ms\n",
      "image 82/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1779_png.rf.d5974a76a1d682f4d0715dd9a709ae95.jpg: 640x640 2 tenchs, 1 electric ray, 1 hen, 6.4ms\n",
      "image 83/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1787_png.rf.b08cab7088aaadebf5a8b191ec41a273.jpg: 640x640 1 stingray, 1 cock, 1 hen, 6.3ms\n",
      "image 84/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1794_png.rf.ddac9eee5d6210676b76251483bc2856.jpg: 640x640 1 tench, 1 hen, 7.3ms\n",
      "image 85/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1795_png.rf.9cba441342aecdfc05c5692519dcd466.jpg: 640x640 1 tench, 1 hen, 11.6ms\n",
      "image 86/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1802_png.rf.92f397b250f3a9896dbe9b60c802f7a6.jpg: 640x640 4 tenchs, 7.9ms\n",
      "image 87/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1812_png.rf.49e13c12bf340bec5153d6ad191d67e1.jpg: 640x640 4 tenchs, 5 cocks, 6.4ms\n",
      "image 88/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1814_png.rf.aa744810df3ec58dd93528b13aafbbec.jpg: 640x640 5 tenchs, 6.2ms\n",
      "image 89/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1818_png.rf.7211d1a16d551f06f5b27680068fc704.jpg: 640x640 58 tenchs, 6.1ms\n",
      "image 90/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1830_png.rf.33f4ffec54ce89fd84e18eb082259422.jpg: 640x640 40 tenchs, 2 cocks, 6.0ms\n",
      "image 91/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1833_png.rf.772f802bf09dab6cbea0b1b374dd3c6c.jpg: 640x640 51 tenchs, 2 cocks, 10.3ms\n",
      "image 92/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1850_png.rf.41edb50587d70f18baaf18edbed38cc6.jpg: 640x640 3 tenchs, 9.6ms\n",
      "image 93/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1853_png.rf.ec4a37cea8585835de4a8cdfac062f67.jpg: 640x640 1 tench, 10.2ms\n",
      "image 94/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1854_png.rf.85aa47ecbafbe6431cdc38eaebd0d207.jpg: 640x640 3 tenchs, 7.6ms\n",
      "image 95/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1859_png.rf.a03221a28682af68a6ad8ddbf1139c52.jpg: 640x640 2 tenchs, 7.4ms\n",
      "image 96/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1865_png.rf.c387b14b74f40db9515bf40a9dfcd277.jpg: 640x640 2 tenchs, 11.2ms\n",
      "image 97/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/1866_png.rf.2893549760fbc3c97e71aaf599e0fae4.jpg: 640x640 3 tenchs, 11.6ms\n",
      "image 98/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/199_png.rf.48885c23a3b0f0b3564b782cdaff7a17.jpg: 640x640 (no detections), 7.7ms\n",
      "image 99/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/208_png.rf.a9878e62482ac49f00941ec6b256a4b3.jpg: 640x640 2 hens, 7.5ms\n",
      "image 100/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/26_png.rf.25a47580056710eb3fb0e2b5a25ccc69.jpg: 640x640 2 tenchs, 1 electric ray, 1 hen, 7.3ms\n",
      "image 101/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/270_png.rf.6cc922d325fce69d3578f3664a4a2559.jpg: 640x640 1 tench, 7.3ms\n",
      "image 102/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/284_png.rf.1712c80458d1c09bfa0eb5f883819f02.jpg: 640x640 1 hen, 16.3ms\n",
      "image 103/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/287_png.rf.3d3fd6950e6d8e5fe79856999ad9fcb6.jpg: 640x640 1 hen, 8.7ms\n",
      "image 104/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/288_png.rf.c1264025c99bc600cf49a94a666b3737.jpg: 640x640 1 hen, 10.3ms\n",
      "image 105/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/292_png.rf.1816cab7491b81268c8dc24fdc46d337.jpg: 640x640 1 hen, 7.6ms\n",
      "image 106/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/294_png.rf.f1a4c492db982c1fdf3cd84535e2ecee.jpg: 640x640 1 hen, 7.4ms\n",
      "image 107/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/308_png.rf.d770a017dd9c67cfe7253884d7f04912.jpg: 640x640 1 tench, 10.1ms\n",
      "image 108/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/325_png.rf.280402b7cdfb62936df4e2abe8290280.jpg: 640x640 2 tenchs, 8.8ms\n",
      "image 109/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/330_png.rf.28dc5ab60a482df4778b7cc82e478723.jpg: 640x640 1 tench, 7.0ms\n",
      "image 110/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/332_png.rf.ded356dfc91f8210150e596fa67d838e.jpg: 640x640 1 tench, 6.3ms\n",
      "image 111/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/346_png.rf.58b40a185eeba0f69a806e4295c43618.jpg: 640x640 1 tench, 5.8ms\n",
      "image 112/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/34_png.rf.83d6a77ea03c6585c7ff68d44d387302.jpg: 640x640 1 tench, 1 electric ray, 1 hen, 6.1ms\n",
      "image 113/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/351_png.rf.6b27af749d42bd8f50602f54bd5e89e2.jpg: 640x640 (no detections), 11.0ms\n",
      "image 114/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/361_png.rf.6ea0ac49a7dfd2b771ecc9bb342febe4.jpg: 640x640 1 tench, 9.9ms\n",
      "image 115/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/391_png.rf.675403cfe046244543d4e5c00d1bd42f.jpg: 640x640 (no detections), 11.3ms\n",
      "image 116/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/393_png.rf.282c08d45e38595e9d152fa9c5650783.jpg: 640x640 1 stingray, 6.6ms\n",
      "image 117/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/394_png.rf.18a0e5fee80b8f7bdf1eaa3bdb0312dc.jpg: 640x640 1 stingray, 6.5ms\n",
      "image 118/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/398_png.rf.d74846c2aada2f494d55becc18aff3ae.jpg: 640x640 1 stingray, 8.2ms\n",
      "image 119/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/402_png.rf.bc755072c793f5863ad3c3cacacf4dce.jpg: 640x640 1 stingray, 10.3ms\n",
      "image 120/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/405_png.rf.a2fab1e2c62080af0c681607e61d18f5.jpg: 640x640 1 stingray, 7.2ms\n",
      "image 121/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/41_png.rf.33b8b2b08f7548baf1a30885a8197d9c.jpg: 640x640 2 tenchs, 1 electric ray, 1 hen, 6.4ms\n",
      "image 122/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/425_png.rf.9ed28798964cb1d76fd531d66f0e18e5.jpg: 640x640 1 stingray, 6.2ms\n",
      "image 123/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/429_png.rf.f7b4b6385bbd8f8a7f588663786faeeb.jpg: 640x640 1 stingray, 6.1ms\n",
      "image 124/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/443_png.rf.30fd052d2af34789b7aa4adb1bb9c947.jpg: 640x640 1 stingray, 6.1ms\n",
      "image 125/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/452_png.rf.9aaf084efe8bdb3048ff40148c38e874.jpg: 640x640 1 stingray, 10.5ms\n",
      "image 126/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/457_png.rf.3a879b653bf3471447577610a645ae39.jpg: 640x640 1 stingray, 7.8ms\n",
      "image 127/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/464_png.rf.bd147a2b521b7cd7168909481269eec1.jpg: 640x640 1 stingray, 8.8ms\n",
      "image 128/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/483_png.rf.dd2b3edbdef75a871d4404c1a1bdb9e0.jpg: 640x640 1 tench, 6.4ms\n",
      "image 129/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/485_png.rf.6c09d1ed207df1cd46f9b71a44c764c4.jpg: 640x640 1 tench, 6.3ms\n",
      "image 130/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/499_png.rf.e9b7d4653d4ad0dcfdd20d261b209f9d.jpg: 640x640 1 tench, 10.0ms\n",
      "image 131/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/4_png.rf.91a444a59f039bd7e618d34f369dcd4b.jpg: 640x640 3 tenchs, 1 hen, 12.0ms\n",
      "image 132/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/516_png.rf.4d7c94e84ea5e0ae96b6060c18a5475e.jpg: 640x640 2 tenchs, 1 stingray, 7.4ms\n",
      "image 133/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/554_png.rf.3fa8fa8ac52693cc0b1d053e4b51ba84.jpg: 640x640 (no detections), 6.8ms\n",
      "image 134/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/556_png.rf.e42ea163629bd306bab8cb404e1e0b12.jpg: 640x640 (no detections), 6.3ms\n",
      "image 135/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/570_png.rf.2dbd7d939f911f989067370e93363e7f.jpg: 640x640 1 stingray, 6.3ms\n",
      "image 136/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/581_png.rf.a37c5e2dd390cf9c80e2c5c55714e7ed.jpg: 640x640 1 stingray, 8.0ms\n",
      "image 137/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/588_png.rf.855671c39c1314bd074c3cf6554d8ece.jpg: 640x640 1 stingray, 9.9ms\n",
      "image 138/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/611_png.rf.133424fb870291331157d031e3cd1e5e.jpg: 640x640 1 tench, 12.7ms\n",
      "image 139/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/627_png.rf.1bce09a298f589c5c3a06b32e75106c9.jpg: 640x640 1 tench, 7.0ms\n",
      "image 140/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/62_png.rf.1bfeb70efc39da1bfc9e203f08e3eb71.jpg: 640x640 3 tenchs, 1 goldfish, 2 hens, 6.4ms\n",
      "image 141/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/634_png.rf.d914afe9bb4947a322cfeb0edd696729.jpg: 640x640 1 tench, 6.2ms\n",
      "image 142/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/640_png.rf.31e673b200431613829a3c0a194c13e3.jpg: 640x640 2 tenchs, 10.0ms\n",
      "image 143/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/649_png.rf.f5f19929ed6d48c0a426582bfe1759ba.jpg: 640x640 2 tenchs, 9.8ms\n",
      "image 144/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/653_png.rf.0359798ebd923e7b64a5ced7804676b1.jpg: 640x640 1 tench, 6.7ms\n",
      "image 145/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/666_png.rf.8f23e0e8cf278ebd7b2f6626d156e0f1.jpg: 640x640 2 tenchs, 6.4ms\n",
      "image 146/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/670_png.rf.ffd2e8fabfc046a1a2a64f97d50e15ee.jpg: 640x640 1 tench, 6.3ms\n",
      "image 147/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/676_png.rf.6a576ec5eb1a08aac18adee1e8edf80f.jpg: 640x640 3 tenchs, 9.6ms\n",
      "image 148/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/680_png.rf.c6ea6d85dd514753e308080c4d475de0.jpg: 640x640 3 tenchs, 9.6ms\n",
      "image 149/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/695_png.rf.8bf473fc9d98441db30b223133f06108.jpg: 640x640 1 tench, 8.7ms\n",
      "image 150/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/699_png.rf.7c6bcb7cb124f66a10f19b20908bae3d.jpg: 640x640 2 tenchs, 10.4ms\n",
      "image 151/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/704_png.rf.6e046fe7d551e6f226a4c7c3b6935be3.jpg: 640x640 1 tench, 6.6ms\n",
      "image 152/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/712_png.rf.846de4e23a5c38376ebe8bd2e58a897c.jpg: 640x640 1 tench, 1 goldfish, 6.3ms\n",
      "image 153/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/716_png.rf.df2847b5085305922f76319150273fdd.jpg: 640x640 1 tench, 6.2ms\n",
      "image 154/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/730_png.rf.16749fbfe349dc8716f433eb30b2c060.jpg: 640x640 1 tench, 10.4ms\n",
      "image 155/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/744_png.rf.0f16baf79492f87b3e0f1b43b0eec4b6.jpg: 640x640 3 tenchs, 10.2ms\n",
      "image 156/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/750_png.rf.cca711518a033fbbd9d3fd6f98062603.jpg: 640x640 2 tenchs, 7.2ms\n",
      "image 157/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/756_png.rf.3a10903601e37d8528c26e9cc755741a.jpg: 640x640 4 tenchs, 9.0ms\n",
      "image 158/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/757_png.rf.d166d93f1ef3b36679b808057a2b29df.jpg: 640x640 5 tenchs, 6.1ms\n",
      "image 159/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/761_png.rf.d0d3249156762c132a44caa8d52d6f31.jpg: 640x640 3 tenchs, 6.1ms\n",
      "image 160/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/772_png.rf.595449b190aee7c9b54b98c15e286071.jpg: 640x640 2 tenchs, 7.6ms\n",
      "image 161/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/795_png.rf.886e90f77cae90ae4787185bb91cc35c.jpg: 640x640 1 tench, 10.8ms\n",
      "image 162/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/79_png.rf.e7a6bb3590606466986563e455d1cfbe.jpg: 640x640 22 tenchs, 10 cocks, 1 hen, 7.8ms\n",
      "image 163/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/7_png.rf.ba481ab66f3c8abb3691c968cfb69a2b.jpg: 640x640 2 tenchs, 1 electric ray, 1 hen, 6.4ms\n",
      "image 164/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/803_png.rf.fe64b6c7f0674fa92d7b1ff67ac0bb4b.jpg: 640x640 2 tenchs, 8.7ms\n",
      "image 165/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/810_png.rf.2872f3eb64a0e9048bdb762e346ac0cb.jpg: 640x640 3 tenchs, 8.7ms\n",
      "image 166/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/833_png.rf.43c58866197b664d55487a214d82cc35.jpg: 640x640 2 tenchs, 10.5ms\n",
      "image 167/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/850_png.rf.034669519322a2a491ae540d90c51442.jpg: 640x640 2 tenchs, 10.2ms\n",
      "image 168/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/865_png.rf.a2883b19f8027c500c61bb25d2254a7a.jpg: 640x640 8 tenchs, 6.7ms\n",
      "image 169/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/86_png.rf.0a932aab5d55c095ae4f62962008761d.jpg: 640x640 22 tenchs, 1 cock, 6.4ms\n",
      "image 170/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/875_png.rf.6bcfbade2a59a7edc6c3052c5595488f.jpg: 640x640 14 tenchs, 6.3ms\n",
      "image 171/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/876_png.rf.3248cf2933cdc5a50fb9ac4454c8a16d.jpg: 640x640 12 tenchs, 8.7ms\n",
      "image 172/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/87_png.rf.9f40487e1637da07e9e492df9b531ca8.jpg: 640x640 20 tenchs, 1 cock, 9.7ms\n",
      "image 173/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/882_png.rf.780fb8dd77a65a97cf9d9e8054747499.jpg: 640x640 1 tench, 7.1ms\n",
      "image 174/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/887_png.rf.c48b82ddb893a22b5565120ff7a755f9.jpg: 640x640 2 tenchs, 6.5ms\n",
      "image 175/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/892_png.rf.863f671102a67f339a517be67d565239.jpg: 640x640 3 tenchs, 6.3ms\n",
      "image 176/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/919_png.rf.c3ac04593ce22545e5a6c9f8b103cc38.jpg: 640x640 1 tench, 1 goldfish, 6.2ms\n",
      "image 177/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/930_png.rf.442cc1e3085243f7bf55de38ae8a35dd.jpg: 640x640 1 goldfish, 11.5ms\n",
      "image 178/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/934_png.rf.fd599824203f9bca8989148ec05a563a.jpg: 640x640 1 goldfish, 10.2ms\n",
      "image 179/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/938_png.rf.e7b8f079d7eaf591b82c3c04aec523fd.jpg: 640x640 1 goldfish, 9.7ms\n",
      "image 180/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/940_png.rf.7cbaf1390789b5d1aed7b68999d76cb5.jpg: 640x640 1 goldfish, 6.8ms\n",
      "image 181/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/95_png.rf.bc1de6abc836344f0c8425afb0460ad5.jpg: 640x640 24 tenchs, 5 cocks, 6.5ms\n",
      "image 182/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/963_png.rf.0125fdcfec91fe5c8cce01651edd7d7e.jpg: 640x640 2 tenchs, 1 goldfish, 6.5ms\n",
      "image 183/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/964_png.rf.77cafbb9ff4c7e9673af786d5854776c.jpg: 640x640 2 tenchs, 1 goldfish, 11.0ms\n",
      "image 184/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/965_png.rf.312eea45c4da9e6cf6b9b2b89b6633c7.jpg: 640x640 2 tenchs, 1 goldfish, 7.5ms\n",
      "image 185/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/970_png.rf.39dc60a6b3cdfa3ac1b2f0d76b4c8530.jpg: 640x640 (no detections), 6.7ms\n",
      "image 186/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/983_png.rf.f9fe3f5df8b074b5a1981276320786ed.jpg: 640x640 1 white shark, 7.5ms\n",
      "image 187/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/984_png.rf.f71ebd95757abb846480427476b4a589.jpg: 640x640 1 white shark, 6.5ms\n",
      "image 188/188 /home/anderste/ikt450-deep-neural-networks/DNN-prosjekt/test/images/991_png.rf.601712257be564c32c4cea71f7191cea.jpg: 640x640 1 white shark, 6.5ms\n",
      "Speed: 2.4ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29545/1557682900.py:71: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colormap = cm.get_cmap('hsv', num_classes)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'synset_to_class_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m synset_id \u001b[38;5;241m=\u001b[39m class_names[idx]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Map synset ID to human-readable class name\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m class_name \u001b[38;5;241m=\u001b[39m \u001b[43msynset_to_class_name\u001b[49m\u001b[38;5;241m.\u001b[39mget(synset_id, synset_id)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Update class_names with human-readable name\u001b[39;00m\n\u001b[1;32m     79\u001b[0m class_names[idx] \u001b[38;5;241m=\u001b[39m class_name\n",
      "\u001b[0;31mNameError\u001b[0m: name 'synset_to_class_name' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import json\n",
    "import urllib.request\n",
    "import yaml\n",
    "\n",
    "# File paths for training, validation, and test images\n",
    "train_images_path = \"./train/images\"\n",
    "test_images_path = \"./test/images\"\n",
    "val_images_path = \"./val/images\"\n",
    "\n",
    "yaml_file_path = \"./data.yaml\"\n",
    "\n",
    "# Load YOLO models with pretrained weights\n",
    "object_detection_model_path = \"weights/yolov8n.pt\"\n",
    "classification_model_path = \"weights/yolov8n-cls.pt\"\n",
    "\n",
    "object_detection = YOLO(object_detection_model_path)\n",
    "classification = YOLO(classification_model_path)\n",
    "\n",
    "class_names = []\n",
    "\n",
    "with open(yaml_file_path, \"r\") as f:\n",
    "    class_names = yaml.safe_load(f)['names']\n",
    "    \n",
    "classification.model.names = class_names # {0: 'n01440764', 1: 'n01443537', ...}\n",
    "\n",
    "# Train the YOLO model\n",
    "epochs = 20\n",
    "learning_rate = 0.0001\n",
    "\n",
    "print(f\"Starting training with YAML: {yaml_file_path}\")\n",
    "detection_results = object_detection.train(\n",
    "    data=yaml_file_path, epochs=epochs, lr0=learning_rate, batch=60, imgsz=640\n",
    ")\n",
    "\n",
    "# Perform predictions on the test images\n",
    "detection_prediction_results = object_detection.predict(test_images_path, imgsz=640)\n",
    "\n",
    "# Initialize lists to store images\n",
    "original_images = []\n",
    "processed_images = []\n",
    "\n",
    "# Download and load the ImageNet class index\n",
    "#class_index_url = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n",
    "#with urllib.request.urlopen(class_index_url) as url:\n",
    "#    imagenet_class_index = json.loads(url.read().decode())\n",
    "\n",
    "# Create a mapping from synset IDs to class names\n",
    "#synset_to_class_name = {}\n",
    "#for idx in imagenet_class_index:\n",
    "#    synset_id, class_name = imagenet_class_index[idx]\n",
    "#    synset_to_class_name[synset_id] = class_name.replace('_', ' ')  # Replace underscores with spaces\n",
    "\n",
    "# Get class names from classification model (synset IDs)\n",
    "#class_names = classification.model.names  # {0: 'n01440764', 1: 'n01443537', ...}\n",
    "#print(f'Class names: {class_names}')\n",
    "#break\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Assign a unique color to each class using a colormap and update class names to human-readable\n",
    "colors = {}\n",
    "colormap = cm.get_cmap('hsv', num_classes)\n",
    "\n",
    "for idx in range(num_classes):\n",
    "    # Get the synset ID\n",
    "    synset_id = class_names[idx]\n",
    "    # Map synset ID to human-readable class name\n",
    "    class_name = synset_to_class_name.get(synset_id, synset_id)\n",
    "    # Update class_names with human-readable name\n",
    "    class_names[idx] = class_name\n",
    "    # Normalize the index for the colormap\n",
    "    color = colormap(idx / num_classes)\n",
    "    # Convert from RGBA to BGR (OpenCV uses BGR format)\n",
    "    color_bgr = (\n",
    "        int(color[2] * 255),  # Blue\n",
    "        int(color[1] * 255),  # Green\n",
    "        int(color[0] * 255),  # Red\n",
    "    )\n",
    "    colors[idx] = color_bgr\n",
    "\n",
    "# Iterate over detections\n",
    "for result in detection_prediction_results:\n",
    "    # Get the original image\n",
    "    original_image = result.orig_img.copy()\n",
    "    processed_image = original_image.copy()\n",
    "\n",
    "    # Check if there are any detections\n",
    "    if result.boxes:\n",
    "        for box in result.boxes:\n",
    "            # Get x1, y1, x2, y2 coordinates\n",
    "            coords = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            x1, y1, x2, y2 = coords\n",
    "            # Ensure coordinates are within image bounds\n",
    "            h, w = processed_image.shape[:2]\n",
    "            x1 = max(0, min(x1, w - 1))\n",
    "            x2 = max(0, min(x2, w - 1))\n",
    "            y1 = max(0, min(y1, h - 1))\n",
    "            y2 = max(0, min(y2, h - 1))\n",
    "            # Crop the RoI\n",
    "            roi = processed_image[y1:y2, x1:x2]\n",
    "\n",
    "            # Run classification on the RoI\n",
    "            classification_results = classification.predict(roi, verbose=False)\n",
    "            # Get class probabilities\n",
    "            class_probs = classification_results[0].probs  # Probs object\n",
    "            # Get the class ID with the highest probability\n",
    "            class_id = int(class_probs.top1)\n",
    "            class_name = class_names[class_id]\n",
    "\n",
    "            # Get the color for this class\n",
    "            color = colors[class_id]\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(processed_image, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(\n",
    "                processed_image,\n",
    "                class_name,\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.9,\n",
    "                color,\n",
    "                2,\n",
    "            )\n",
    "    else:\n",
    "        # If no detections, add a note\n",
    "        cv2.putText(\n",
    "            processed_image,\n",
    "            \"No Detections\",\n",
    "            (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1.0,\n",
    "            (0, 0, 255),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "    # Append images to the lists\n",
    "    original_images.append(original_image)\n",
    "    processed_images.append(processed_image)\n",
    "\n",
    "# Display images side by side without subplots\n",
    "for idx in range(len(original_images)):\n",
    "    # Convert BGR to RGB for displaying with matplotlib\n",
    "    original_rgb = cv2.cvtColor(original_images[idx], cv2.COLOR_BGR2RGB)\n",
    "    processed_rgb = cv2.cvtColor(processed_images[idx], cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Concatenate images horizontally\n",
    "    concatenated_image = np.hstack((original_rgb, processed_rgb))\n",
    "\n",
    "    # Display the concatenated image\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(concatenated_image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Image Pair {idx + 1}: Original (Left) and Processed (Right)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81441cff-1866-430f-8fde-2d02bee37083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
